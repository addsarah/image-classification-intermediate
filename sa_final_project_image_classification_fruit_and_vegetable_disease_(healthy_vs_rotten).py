# -*- coding: utf-8 -*-
"""SA Final Project: Image Classification Fruit and Vegetable Disease (Healthy vs Rotten).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Xl6TZHuyQ_n5zSboZm3WfWIRFTPjadS-

# Proyek Klasifikasi Gambar: Fruit and Vegetable Disease (Healthy vs Rotten)

- **Nama:** Sarah Adibah
- **Email:** sarahadibah06@gmail.com
- **ID Dicoding:** [addsarah](https://www.dicoding.com/users/addsarah/academies)

**Submission Proyek CNN untuk Klasifikasi Gambar** mengharuskan peserta menggunakan dataset gambar dengan minimal 1.000 sampel yang belum pernah digunakan sebelumnya. Dataset harus dibagi menjadi train set, test set, dan validation set untuk memastikan evaluasi model yang objektif.

Model yang dibangun harus menggunakan arsitektur **Sequential** dengan lapisan **Conv2D** dan **Pooling** dalam Keras, serta mencapai akurasi minimal **85%** pada training dan testing set. Selain itu, peserta wajib membuat **plot akurasi dan loss** selama proses training untuk memvisualisasikan performa model.

Sebagai bagian dari submission, model harus disimpan dalam tiga format: **SavedModel, TF-Lite, dan TFJS**, agar dapat digunakan di berbagai platform seperti server, perangkat mobile, dan aplikasi berbasis JavaScript.

Untuk mendapatkan nilai tinggi, peserta disarankan menerapkan **callback**, menggunakan dataset lebih besar (≥10.000 gambar), mencapai akurasi ≥95%, serta memiliki minimal tiga kelas. Submission harus mencakup **notebook pelatihan model (`.ipynb`), dataset, dan file hasil kompresi (zip)** agar dapat langsung dievaluasi oleh reviewer tanpa perlu eksekusi ulang.

# **1. Library Install**
"""

!pip install split-folders tensorflow==2.15.0 tensorflowjs

"""# **2. Library Import**"""

# Commented out IPython magic to ensure Python compatibility.
import os
import shutil
import zipfile
import pathlib
import numpy as np
import tensorflow as tf
import splitfolders as sf

from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications import VGG16
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import GlobalAveragePooling2D, Conv2D, MaxPool2D, Flatten, Dense
from google.colab import files, userdata

import matplotlib.pyplot as plt
import matplotlib.image as mpimg
# %matplotlib inline

print(f'TensorFlow version: {tf.__version__}')

"""# **3. Data Loading**"""

# Kaggle username and key
os.environ['KAGGLE_USERNAME'] = 'addsarah'
os.environ['KAGGLE_KEY'] = 'eff5b83c0a0943cd628b2c66f0878a19'

# Download dataset from Kaggle
!kaggle datasets download -d muhammad0subhan/fruit-and-vegetable-disease-healthy-vs-rotten

# Unzip the downloaded zip file
local_zip = 'fruit-and-vegetable-disease-healthy-vs-rotten.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall()
zip_ref.close()

# List directory
base_dir = 'Fruit And Vegetable Diseases Dataset'
labels = os.listdir(base_dir)
labels

# Dictionary to store folder name and count of images
folder_counts = {}

for folder in os.listdir(base_dir):
    folder_path = os.path.join(base_dir, folder)
    if os.path.isdir(folder_path):  # Ensure it's a directory
        file_count = len([f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))])
        folder_counts[folder] = file_count

# Print the results
for folder, count in folder_counts.items():
    print(f"{folder}: {count} images")

"""# **4. Data Preparation**"""

# Remove unused image data folder
shutil.rmtree(base_dir + '/Bellpepper__Healthy')
shutil.rmtree(base_dir + '/Bellpepper__Rotten')
shutil.rmtree(base_dir + '/Carrot__Healthy')
shutil.rmtree(base_dir + '/Carrot__Rotten')
shutil.rmtree(base_dir + '/Cucumber__Healthy')
shutil.rmtree(base_dir + '/Cucumber__Rotten')
shutil.rmtree(base_dir + '/Grape__Healthy')
shutil.rmtree(base_dir + '/Grape__Rotten')
shutil.rmtree(base_dir + '/Guava__Healthy')
shutil.rmtree(base_dir + '/Guava__Rotten')
shutil.rmtree(base_dir + '/Jujube__Healthy')
shutil.rmtree(base_dir + '/Jujube__Rotten')
shutil.rmtree(base_dir + '/Orange__Healthy')
shutil.rmtree(base_dir + '/Orange__Rotten')
shutil.rmtree(base_dir + '/Pomegranate__Healthy')
shutil.rmtree(base_dir + '/Pomegranate__Rotten')
shutil.rmtree(base_dir + '/Potato__Healthy')
shutil.rmtree(base_dir + '/Potato__Rotten')
shutil.rmtree(base_dir + '/Mango__Healthy')
shutil.rmtree(base_dir + '/Mango__Rotten')
shutil.rmtree(base_dir + '/Tomato__Healthy')
shutil.rmtree(base_dir + '/Tomato__Rotten')

labels = os.listdir(base_dir)
labels

categories = ['Strawberry', 'Apple', 'Banana']

# Create merged directories
for category in categories:
    merged_folder = os.path.join(base_dir, category)
    os.makedirs(merged_folder, exist_ok=True)

    # Move healthy and rotten images into the merged folder
    for variant in ['Healthy', 'Rotten']:
        source_folder = os.path.join(base_dir, f"{category}__{variant}")
        if os.path.exists(source_folder):
            for file in os.listdir(source_folder):
                source_path = os.path.join(source_folder, file)
                destination_path = os.path.join(merged_folder, file)
                shutil.move(source_path, destination_path)
            os.rmdir(source_folder)  # Remove empty source folder

print("Folders merged successfully!")

for category in categories:
    merged_folder = os.path.join(base_dir, category)
    os.makedirs(merged_folder, exist_ok=True)

    for variant in ['Healthy', 'Rotten']:
        source_folder = os.path.join(base_dir, f"{category}__{variant}")
        if os.path.exists(source_folder):
            for file in os.listdir(source_folder):
                shutil.move(os.path.join(source_folder, file), os.path.join(merged_folder, file))
            os.rmdir(source_folder)  # Remove empty source folder

# Count images in each folder
image_counts = {category: len(os.listdir(os.path.join(base_dir, category))) for category in categories}

# Plot the distribution
plt.figure(figsize=(8, 3))
bars = plt.barh(list(image_counts.keys()), list(image_counts.values()), color=['#0072BD', '#D95319', '#EDB120'])

# Add text labels on bars
for bar in bars:
    plt.text(bar.get_width(), bar.get_y() + bar.get_height() / 2, int(bar.get_width()), ha='left', va='center')

plt.xlabel('Count')
plt.ylabel('Class')
plt.title('Distribution of Images in Dataset')
plt.grid(color='lightgray', linestyle='-', linewidth=0.7, which='major')
plt.grid(color='lightgray', linestyle='--', linewidth=0.4, which='minor')
plt.minorticks_on()
plt.show()

"""# **5. Train-Val Split**"""

# Split directory
sf.ratio(
    base_dir,
    output=os.path.join('image'),
    seed=None,
    ratio=(0.8, 0.1, 0.1)
)

def count_images_in_directory(directory):
    labels = os.listdir(directory)
    image_counts = {}
    for label in labels:
        folder_path = os.path.join(directory, label)
        image_files = os.listdir(folder_path)
        image_counts[label] = len(image_files)
    return image_counts

train_dir = os.path.join('image', 'train')
val_dir = os.path.join('image', 'val')
test_dir = os.path.join('image', 'test')

train_counts = count_images_in_directory(train_dir)
val_counts = count_images_in_directory(val_dir)
test_counts = count_images_in_directory(test_dir)

labels = list(train_counts.keys())
train_values = list(train_counts.values())
val_values = list(val_counts.values())
test_values = list(test_counts.values())

y = range(len(labels))

plt.figure(figsize=(8, 3))

bars1 = plt.barh(y, train_values, height=0.4, label='Train', align='center')
bars2 = plt.barh([i + 0.4 for i in y], val_values, height=0.4, label='Validation', align='center')
bars3 = plt.barh([i + 0.4 for i in y], test_values, height=0.2, label='Test', align='center', color='#EDB120')

plt.xlabel('Count')
plt.ylabel('Class')
plt.title('Distribution of Images in Train and Validation Sets')
plt.yticks([i + 0.2 for i in y], labels)
plt.grid(color='lightgray', linestyle='-', linewidth=0.7, which='major')
plt.grid(color='lightgray', linestyle='--', linewidth=0.4, which='minor')
plt.minorticks_on()
plt.legend()

for bar in bars1:
    width = bar.get_width()
    plt.text(width, bar.get_y() + bar.get_height() / 2, int(width), ha='left', va='center')

for bar in bars2:
    width = bar.get_width()
    plt.text(width, bar.get_y() + bar.get_height() / 2, int(width), ha='left', va='center')

for bar in bars3:
    width = bar.get_width()
    plt.text(width, bar.get_y() + bar.get_height() / 2, int(width), ha='left', va='center')

plt.show()

"""# **6. Image Augmentation**"""

print(os.listdir(train_dir))
print(os.listdir(val_dir))
print(os.listdir(test_dir))

# Image Augmentation to artificially generate new data
train_datagen = ImageDataGenerator(
    rescale=1./255,
    zoom_range=0.2,
    shear_range=0.2,
    rotation_range=30,
    horizontal_flip=True,
    fill_mode='nearest',
)

val_datagen = ImageDataGenerator(
    rescale=1./255
)

test_datagen = ImageDataGenerator(
    rescale=1./255,
)

# Preperation the training and validation data
train_gen = train_datagen.flow_from_directory(
    train_dir,
    target_size=(224, 224),
    batch_size=50,
    shuffle=True,
    color_mode='rgb',
    class_mode='categorical',
)

val_gen = val_datagen.flow_from_directory(
    val_dir,
    target_size=(224, 224),
    batch_size=50,
    shuffle=True,
    color_mode='rgb',
    class_mode='categorical',
)

test_gen = test_datagen.flow_from_directory(
    test_dir,
    target_size=(224, 224),
    batch_size=50,
    shuffle=False,
    color_mode='rgb',
    class_mode='categorical',
)

"""# **7. Model Development**"""

base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
base_model.trainable = False

base_model.summary()
print(f'Base Model Layer : {len(base_model.layers)}')

model = Sequential()

model.add(base_model)
model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))
model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))
model.add(Flatten())
model.add(Dense(64, activation='relu'))
model.add(Dense(3, activation='softmax'))

model.summary()
print(f'Model Layer : {len(model.layers)}')

"""https://github.com/keras-team/keras/issues/19982

https://github.com/tensorflow/tensorflow/issues/65436
"""

model.compile(
    loss='categorical_crossentropy',
    optimizer='adam',
    metrics=['accuracy']
)

# Stop training callback
class stopCallback(tf.keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs={}):
        if (logs.get('accuracy') > 0.95 and logs.get('val_accuracy') > 0.95):
            print('\nAccuracy and Validation Accuracy reach > 95%')
            self.model.stop_training = True

stopTraining = stopCallback()

# ReduceLROnPlateau callback
reduceLROP = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=2)

# Model training
history = model.fit(
    train_gen,
    epochs=5,
    validation_data=val_gen,
    verbose=1,
    callbacks=[stopTraining, reduceLROP]
)

# @title **Model Accuracy and Loss Plot**
plt.figure(figsize=(9, 3))

plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy Plot')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend(loc='lower right')
plt.grid(color='lightgray', linestyle='-', linewidth=1, which='major')
plt.grid(color='lightgray', linestyle='--', linewidth=0.5, which='minor')
plt.minorticks_on()

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss Plot')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend(loc='upper right')
plt.grid(color='lightgray', linestyle='-', linewidth=1, which='major')
plt.grid(color='lightgray', linestyle='--', linewidth=0.5, which='minor')
plt.minorticks_on()

plt.show()

model.evaluate(test_gen)

"""# **8. Model Inference Testing**"""

train_gen.class_indices

# @title **Prepare Image**
def prepare_image(img_path, target_size=(224, 224)):
    img = image.load_img(img_path, target_size=target_size)
    imgplot = plt.imshow(img)
    x = image.img_to_array(img)
    x = np.expand_dims(x, axis=0)
    images = np.vstack([x])
    return images

"""## **8.1. Saved Model**"""

def saved_model_inference(model_dir, input_img_array):
    loaded_model = tf.saved_model.load(model_dir)
    inference = loaded_model.signatures['serving_default']
    in_tensor = tf.convert_to_tensor(input_img_array, dtype=tf.float32)
    output = np.argmax(inference(in_tensor))

    if output == 0:
        print('Image prediction: Apple')
    elif output == 1:
        print('Image prediction: Banana')
    elif output == 2:
        print('Image prediction: Strawberry')

saved_model_inference(export_dir, prepare_image(next(iter(files.upload().keys()))))

"""## **8.2. TensorFlow Lite**"""

def tf_lite_inference(model_dir, input_img_array):
    interpreter = tf.lite.Interpreter(model_path="model.tflite")
    interpreter.allocate_tensors()

    input_details = interpreter.get_input_details()
    output_details = interpreter.get_output_details()

    interpreter.set_tensor(input_details[0]['index'], input_img_array)
    interpreter.invoke()

    classes = interpreter.get_tensor(output_details[0]['index'])
    output = np.argmax(classes)

    if output == 0:
        print('Image prediction: Apple')
    elif output == 1:
        print('Image prediction: Banana')
    elif output == 2:
        print('Image prediction: Strawberry')

tf_lite_inference('model.tflite', prepare_image(next(iter(files.upload().keys()))))

"""# **9. Model Deployment Conversion**

## **9.1. Saved Model**
"""

export_dir = 'saved_model/'
tf.saved_model.save(model, export_dir)
!ls saved_model

"""## **9.2. HDF5 Model**"""

model.save('model.keras')

"""## **9.3. TF-Lite Model**"""

# converter = tf.lite.TFLiteConverter.from_keras_model(export)
converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)
tflite_model = converter.convert()

# Save the TF-Lite model
with open('model.tflite', 'wb') as t:
    t.write(tflite_model)

"""## **9. 4. TensorFlow.js Model**"""

!tensorflowjs_converter \
    --input_format=tf_saved_model \
    /content/saved_model/ \
    /content/tfjs_model

"""# **10. Export Model**"""

labels = ['Apple', 'Banana', 'Strawberry']

with open('label.txt', 'w') as f:
    for label in labels:
        f.write(label + '\n')

!pip freeze > requirements.txt
!zip -r saved_model.zip saved_model/
!zip -r tfjs_model.zip tfjs_model/

zip_name = 'subimageclassification.zip'
download_files = ['saved_model.zip', 'tfjs_model.zip', 'model.tflite',
                  'model.keras', 'requirements.txt', 'label.txt']

with zipfile.ZipFile(zip_name, 'w') as z:
    for file in download_files:
        z.write(file, compress_type=zipfile.ZIP_DEFLATED)